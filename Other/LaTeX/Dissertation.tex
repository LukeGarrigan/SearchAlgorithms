%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Change the option between square brackets
% depending on the document you have to write:
%
% proposal    for the initial proposal
% review      for the literature review
% progress    for the progress report
% final       for the final report
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[final]{cmpreport}
\makeatletter
\input{t1pcr.fd}
\makeatother
\setlength{\footnotesep}{3ex}
\usepackage{listings}
\usepackage{pgfplots}
% Some package I am using. You may not need them
%
\usepackage{rotating}
\usepackage{subfloat}
\usepackage{float}
% packages for algorithms
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}




%\setkeys{Gin}{draft}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  Fill in the fields with:
%
%  your project title
%  your name
%  your registration number
%  your supervisor's name
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{AI search algorithms for the solution of puzzles}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% The author's name is ignored if the following command 
% is not present in the document
%
% Before submitting a PDF of your final report to the 
% project database you may comment out the command
% if you are worried about lack of anonimity.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Luke Garrigan}


\registration{100086495}
\supervisor{Dr Pierre Chardaire}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Fill in the field with your module code.
% this should be:
%
% for BIS            -> CMP-6012Y
% for BUSINESS STATS -> CMP-6028Y
% for other students -> CMP-6013Y
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ccode{CMP-6012Y}


\summary{


}

\acknowledgements{
	
FIrstly, I would like to express my sincere gratitude to my advisor Dr. Pierre Chardaire for the patience, guidance, wisdom and brilliance he has provided throughout my final year. I have been extremely lucky to have
a supervisor who cared so much about my work, and who responded to my questions and queries so
promptly.

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% If you do not want a list of figures and a list of tables
% to appear after the table of content then uncomment this line 
%
% Note that the class file contains code to avoid
% producing an empty list section (e.g list of figures) if the 
% list is empty (i.e. no figure in document).
%
% The command also prevents inserting a list of figures or tables 
% anywhere else in the document
%
% Some supervisors think that a report should not contain these
% lists. Please ask your supervisor's opinion.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\nolist,

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Comment out if you want your list of figures and list of
% tables on two or more pages, in particular if the lists do not fit 
% on a single page.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\onePageLists

\begin{document}



\section{Introduction}



 In computer science a search algorithm is a series of steps that can be used to find a desired state or a path to a particular state. In most scenarios there will be additional constraints that will need to be fulfilled such as the time taken to reach the desired state, memory availability, maximum number of moves. The main difference between informed search and uninformed search is the use of heuristic functions that guide the search towards the goal while avoiding non-promising paths \cite{felner2015early}. Informed search algorithms such as A* \cite{hart1968formal}, IDA* \cite{korf1985depth} are analysed in this paper with various heuristics including Manhattan distance, linear conflict \cite{hansson1985generating} and pattern databases (PDB) \cite{culberson1996searching}. A comparison between informed and uninformed search is made along with an in-depth analysis of different heuristics for specific problem domains such as the sliding-tile puzzle, Towers of Hanoi and the Rubik's cube.

 A classic example in the AI literature of pathfinding problems are the sliding-tiles puzzles such as the $3\times3$ 8-puzzle, the $4\times4$ 15-puzzle and the $5\times5$ 24-puzzle. The 8-puzzle consists of a $3\times3$ grid with eight numbered square tiles and one blank. The blank is used to slide other tiles in which are horizontally or vertically adjacent into that position in an attempt to reach the goal state. The objective is to rearrange the tiles from some random configuration to a specified goal configuration. The number of possible solvable states for the 8-puzzle is $9!/2=181440$ so can be solved by means of brute-force search. However for the 15-puzzle with $16!/2\approx1.05\times10^{13}$ and 25-puzzle with $25!/2\approx7.76\times10^{24}$ a more sophisticated informed search is required.
 
 The Towers of Hanoi puzzle consists of $3$ pegs and $n$ discs all of varying sizes. The discs are initially stacked on the leftmost peg in decreasing order of size with the largest on the bottom. The task is to move all discs from the initial peg to the goal peg without violating two constraints: Only the top disc of any peg can be moved and a larger disc can never be placed on top of a smaller disc. For the $3$ peg problem a simple recursive algorithm can be used to find the solution in the minimum number of moves, however, for the $4$ peg problem (TOH4) the recursive algorithm doesn't find the goal state optimally. The recursive algorithm works by initially moving the $n-1$ smallest discs to the intermediate peg, then moving the $n-1$ largest disc to the goal peg, then move the $n-1$ smallest discs from the intermediate peg to the goal peg. Finding shortest path with this algorithm is not possible with TOH4 because there are two intermediate pegs rather than one and without priori there is no way to determine which peg should be used over the other. This implies the use of systematic search to find the optimal path.
 
 
 

 


\section{Relevant Literature}


\section{Preliminaries}

\section{Design}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{classDiagram}
	\captionsetup{justification=centering}
	\caption{Class Diagram}
\end{figure}


\subsection{Solvability Of Tile Games}
Problem domains may have constraints that can preclude parts of the search space. For example, although the fifteen puzzle has $ 16! \approx 10^{13} $ possible positions, only one half of them can be reached from the goal. \citep{DBLP:journals/ci/CulbersonS98}. 

To determine whether a sliding-tile puzzle is solvable we must calculate the sum of the inversions.
An inversion is when a tile precedes another tile with a smaller number. 
Algorithm 1 was used to create testing states for the sliding-tile puzzle, states with randomised permutations were constructed and then checked to see if they were solvable, once a total of 1000 solvable test cases were created the search algorithms were then experimented with.
\begin{algorithm}
	\caption{Is Current State Solvable}\label{Solvable}
	\begin{algorithmic}[H]
		\Procedure{IsSolvable}{state}
		\State $puzzleLength \gets state.size()$
		\State 	$gridWidth \gets \sqrt{puzzleLength}$
		\State $blankRowEven \gets true$
		\For{$i\gets 1, puzzleLength$}
		\If{$state[i] =0$}
		\State $blankRowEven \gets (i / gridWidth) \bmod 2 = 0$
		\State $\textbf{continue} $
		\For{$j\gets i + 1, puzzleLength$}
		\If{$state[i] > state[j] \textbf{ and } state[j] \not= 0 $}
		\State $parity \gets !parity$
		\EndIf
		\EndFor
		\EndIf 
		\EndFor
		
		\If{$gridWidth \bmod 2 = 0 \textbf{ and } blankRowEven$}
		\State \textbf{return} $!parity$
		\EndIf
		\State \textbf{return} $parity$
		
		\EndProcedure
	\end{algorithmic}	
\end{algorithm}	





\section{Brute-Force Search}
Brute-force search is a general problem-solving technique that consists of systematically enumerating all the possible states for a given solution and checking to see whether that given state satisfies the problem's statement. All that is required to execute a brute-force is some legal operators, an initial state and an acknowledged goal state. 
\subsection{Completeness and Optimality}
 Often in search the input may be an implicit representation of an infinite graph. Given these conditions, a search algorithm is characterised as being complete if it is guaranteed to find a goal state provided one exists. Breadth-first search is complete and when applied to infinite graphs it will eventually find the solution. Depth-first search is not complete and may get lost in parts of the graph that do not contain a goal state.
\subsection{Breadth-First Search}
Breadth-first search expands the nodes in a tree in the order of their given distance from the root, so it expands all the neighbouring nodes before going to the next level of the tree. The algorithm doesn't trawl to the deeper levels of the tree without first expanding the lower levels thus ensures the finding of the shortest path. The amount of time used by breadth-first search is linear to the number of nodes expanded, since each node can be generated in constant time, and is a function of the branching factor $b$ and the solution depth $d$. Since the number of nodes at level $d$ is $b^d$, the total number of nodes generated in the worst case is $O(b^d)$. \citep{DBLP:journals/mima/Korf95}. The space requirement of breadth-first search is its largest deficiency. The 8-tile has a search space of $9!/2=181,400$ states with a maximum number of 31 moves to solve. In terms of practicality, with larger problem states such as the 15-tile puzzle a breadth-first search will exhaust the available memory rather quickly with its $16!/2 = 10,461,394,944,000$ states and a maximum number of 80 moves to solve.

BFS begins by declaring an empty set $s$ which stores all the states that have been expanded. A queue $q$ is then initialised which stores states to be expanded. The initial state is added to both $q$ and $s$, $q$ is then repeatedly looped through until a solution is found or $q$ is empty meaning there are no possible solutions. The $currentState$ is dequeued from $q$, checked against the goal state and returned if a match. Otherwise, each possible move from $currentState$ is found and added to $q$ to be expanded see Algorithm~\ref{BFS}.
	\begin{algorithm}
	\caption{Breadth-First Search}\label{BFS}
	\begin{algorithmic}[1]
		\Procedure{BFS}{$state$}
		\State $s \gets \textit{empty set}$
		\State $q \gets \textit{empty queue}$
		\State $q.add(state)$
		\State $q.enqueue(state)$
		\While{$q \textbf{ is not } empty$}
		\State $currentState \gets q.dequeue()$
		\If {$currentState = goal$}
		\State \textbf{return} $current$
		\EndIf
		\For{$neighbour \textbf{ in } neighbours(currentState)$}	
		\If{$neighbour \text{ is not in } s$}
		\State $s.add(neighbour)$
		\State $q.enqueue(neighbour)$
		\EndIf
		
		\EndFor
		\EndWhile
		\EndProcedure
	\end{algorithmic}
\end{algorithm}








\subsection{Depth-First Search}
Depth-first search (DFS) addresses the limitations of breadth-first by always generating next a child of the deepest unexpanded node. Breadth-first search manages the list as a first-in first-out queue, whereas depth-first search treats the list as a last-in first-out stack. Depth-first search is implemented recursively, with the recursion stack taking the place of an explicit node stack. Given a starting state, depth-first search stores all the unvisited children of that state in a stack. It then removes the top state from the stack and adds all of the removed states children to the stack. Depth first search generates a long sequence of moves, only ever reconsidering a move when it reaches the end of a stack, this can become a serious problem given a graph of significant size and there's only one solution, as it may end up exploring the entire graph on a single DFS path only to find the solution after looking at each node. Worse, if the graph is infinite the search might not terminate.

DFS begins by declaring an empty set $visted$ which stores all the states that stores expanded states. The state is checked against the goal and returned if a match. All possible moves from the current state are looped through and recursively call the function to repeat the process see Algorithm~\ref{dfs}.
\begin{algorithm}
	\caption{DFS}\label{dfs}
	\begin{algorithmic}[1]
		\State $visited \gets empty set$
		\Procedure{DFS}{$state$}
		\If{$state = goal$}
		\State \textbf{return} state
		\EndIf
		\For{$neighbour \textbf{ in } neighbours(state)$}
		\If{$neighbour \textbf{ not in } visited$}
		\State	$DFS(neighbour)$
		\EndIf
		\EndFor
		\State $visited.add(state)$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}


Depth-first search is not the preferred algorithm for solving the sliding-tile puzzle in the minimum number of moves, it would be more preferred in an implementation which has goals in every path. The algorithm was implemented regardless to analyse whether the results match expectation. Table 2 displays the results of the depth-first search implementation, there is no real noticeable pattern in the data apart from they are consistently inconsistent. The results prove that the algorithm doesn't find the goal state in the minimum number of moves which further confirms that DFS should not be used in the sliding-tile problem. 

  
\subsection{Depth-First Search Iterative Deepening}
Depth-First Iterative-Deepening (DFID) is an extension of depth-first search, it combines breadth-first search's completeness and depth-first search's space efficiency. DFID has a maximum depth; searching all possibilities up to the specific depth and if it doesn't find the goal state it increases the depth increases. DFID performs depth-first search to depth one, then starts over and executes a depth-first search to depth two and continues deeper and deeper until a solution is found. The complexity of DFID is only O(d) where d is the depth, this is because at a given point it is executing only a depth-first search and saving only a stack of nodes. DFID ensures that the shortest path to the goal state will be found as does breadth-first search \citep{DBLP:conf/otm/MeissnerB11}.

DFID begins by looping from 0 to the maximum depth of the problem domain. A function is then called with the current state and the specified depth which returns $found$ if the goal state has been discovered or $null$ otherwise. The function depth-limited depth-first search $DLS$ is called, the state is checked against the goal state provided the depth is 0 as the previous depths have already been checked. If the depth is greater than zero each possible move is found and used in a recursive call of $DLS$ with a decremented depth see Algorithm~\ref{DFID}. 

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother



	\begin{algorithm}
	\caption{Depth-First Iterative Deepening}\label{DFID}
	\begin{algorithmic}[1]
		\Procedure{DFID}{state}
		\For{$depth \gets 0, \infty$}
		\State$ found \gets DLS(state, depth)$
		\If{$found \not= null$}
		\State \textbf{return} $found$
		\EndIf
		\EndFor
		\EndProcedure
		
		\Procedure{dls}{state, depth}
		\If{$depth =0 \textbf{ and } state = goal$ }
		\State \textbf{return} $found$
		\EndIf
		
		\If{$depth > 0$}
		\For{$neighbour \textbf{ in } neighbours(state)$}	
		\State $found \gets DLS(neighbour, depth-1)$
		\If{$found \not= null$}
		\State \textbf{return} $found$
		\EndIf
		\EndFor
		\EndIf 
		\State \textbf{return} $null$
		\EndProcedure
	\end{algorithmic}	
\end{algorithm}	

Although DFID maintains the advantage of requiring a comparable supply of memory as depth-first search and doesn't get caught in infinite loops, DFID's time taken to find a solution is vast and generally longer than both depth-first search and breadth-first search, this is because it has to expand the same states multiple times. Table 3 are the results for DFID with the depth preset to the minimum number of moves required to solve the puzzle state. It is clear that the number of nodes expanded is far greater in comparison with breadth-first search shown in Table 1.

\begin{table}[ht]
	\caption{Depth-First Iterative Deepening: 8-Tile}
	\begin{center}
		\begin{tabular}{crrr} \hline
			Min Moves & Moves & Nodes Expanded &Time(ms)  \\ \hline
			5  & 5 & 56 & 0.9521 \\
			10 & 10  &6392&  16.777216 \\ 
			15 & 15 & 3350884& 2902.4583  \\ \hline
		
		\end{tabular}
	\end{center}
\end{table}



\subsection{Evaluation Of Brute-Force Searches}
Depth-first search often induces the possibility of traversing down the left-most path forever, it is also not guaranteed to find the solution and the likelihood that the optimal solution is found is low.

Breadth-first search is very fast when considering the 8-tile puzzle as the search space is small, however it uses too much memory to be useful with larger problems such as the 15-tile puzzle. 

Depth-first iterative deepening is beneficial as it avoids infinite cycling, it obtains the same result as BFS whilst saving memory, however it is very slow as it has to repeatedly expand nodes it has already visited. DFID is only really beneficial when the solution depth is known, else it would have to trawl through all possibilities up to the solution depth and then through all possibilities at the solution depth until it reaches the goal. It is unlikely for the sliding-tile puzzle that the user knows the solution depth, thus implies ample execution time to find the goal state.


\section{Heuristic Search} \label{sec1}
 A heuristic is a function that ranks possible moves at each branching step to decide which branch to follow. The goal of a heuristic is to produce a fast estimation of the cost from the current state to the desired state, the closer the estimation is to the actual cost the more accurate the heuristic function. In the context of the sliding-tile puzzle, to find best move from a set configuration the heuristic function is executed on each of the child states, the child state with the smallest heuristic value is chosen.
 


\subsection{Admissible Heuristics}
A heuristic function is said to be admissible if it never overestimates the cost of reaching the goal, i.e the estimated cost to the goal from the current node is not higher than the lowest possible cost from the current node. The lowest possible cost $h^*(n)$ is the cost of the optimal path from $n$ to a goal node $G$. The heuristic function $h(n)$ is admissible if $0 \leq h(n) \leq h^*(n)$; admissible heuristic functions are optimistic meaning they are lower bounds on the actual cost.

\subsection{Consistent Heuristics}
 A heuristic function is said to be consistent if the cost from the current node $n$ to a successor node $p$, plus the estimated cost from the successor node to the goal state is less than or equal to the estimated cost from the current node to the goal node $h(n)\leq c(n,p) + h(p)$, where $c(n,p)$ is the cost of reaching node $p$ from $n$ and the heuristic value of the goal $G$ is zero $h(G)=0$ (Figure 2). 


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.4\textwidth]{consistent}
	\captionsetup{justification=centering}
	\caption{Consistent Heuristics Diagram}
\end{figure}

\subsection{Heuristic Evaluation Functions}
\subsubsection{Manhattan Distance}
Manhattan distance is the classic heuristic function for the sliding-tile puzzles, for each tile in the puzzle the Manhattan distance counts the number of grid units between its current location
and its goal location and summing these values for all tiles. Manhattan distance is a lower bound on actual solution length, because every tile must move at least its Manhattan distance, and each move only moves one tile. The Manhattan distance is a lower bound for the number of moves required to solve an occurrence of the sliding-tile puzzle, since every tile must move at least as many times as its distance to its goal position. \citep{DBLP:conf/ccgrid/LinnertSB14}.



	
\begin{algorithm}
	\caption{Manhattan Distance}\label{Manhattan Distance}
	\begin{algorithmic}[1]
		\Procedure{ManDist}{$state$}	\Comment{The current puzzle configuration }
		\State$total\gets 0$
		\State$puzzleLength\gets state.size()$
		\State$dimensions\gets \sqrt{puzzleLength}$
		\For{$i\gets 1, puzzleLength$}	\Comment{Loops through each tile of the puzzle}
		\State $tileValue\gets state[i]$
		\State $expectedRow\gets (tileValue -1)\div dimensions$
		\State $expectedCol\gets (tileValue -1)\mod dimensions$
		\State $rowNum \gets i\div dimensions$
		\State $rowNum\gets i \bmod dimensions$
		\State $total\gets total \texttt{+} \mid{expectedRow-rowNum}\mid\texttt{+}\mid{expectedCol-colNum}\mid$
		\EndFor
		\State \textbf{return} $total$\Comment{The heuristic is the total}
		\EndProcedure
	\end{algorithmic}
\end{algorithm}



\subsubsection{Linear Conflict Heuristic}
Linear Conflict heuristic is an improvement to the Manhattan distance, it applies when two tiles are positioned in their desired row or column but are reversed relative to
their goal positions, meaning a given tile must move out of the row or column in order to let the other pass. If there is a linear conflict then an extra two moves will be added to the total sum as the tile which must move, has to transition out of the row or column and then back into its desired position. These two extra moves are not included in the Manhattan distance so can be added to the total without violating admissibility.



Figure 2 displays a visual example the linear conflict heuristic. The initial state shows the first row to be reversed meaning values 1,2 and 3 are positioned 3,2 and 1. The $max$ (maximum value in the row or column) is compared to 3, as 3 is greater than -1 $max$ is now 3. For value 2 it is not larger than the current $max$ 3 meaning a linear conflict thus 2 is added to the total, value 1 is also not larger than 3 so another two is added to the total heuristic value.


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\textwidth]{linear}
	\captionsetup{justification=centering}
	\caption{Calculating Linear Conflict}
\end{figure}



\subsection{A* Algorithm}
A* search is a combination of lowest-cost-first and best-first searches that considers both path cost and heuristic information in its selection of which path to expand. For each path on the frontier, A* uses a heuristic function. This allows A* search to ensure the prioritisation of states in which are more likely to result in a low-cost goal state. The calculation of the heuristic value is dependent on the problem that is being solved. For example, for problems which aim to reach a location the Euclidean distance between the state and the goal is often used as the heuristic. 

The A* algorithm uses $cost(p)$, the cost of the path found, as well as the heuristic function $h(p)$, the estimated path cost from the end of $p$ to the goal. As A* uses admissible heuristic it will always find solutions in the order of their cost. \citep{DBLP:journals/ker/Brewka96}.  A* uses breadth-first traversal thus uses large chunks of memory in comparison to applications that use depth-first traversal. The performance of A* is also heavily reliant on the accuracy of the heuristic.

A* begins by declaring two empty sets: $closedSet$ stores states that have already been visited; $openSet$ contains states to be visited. The initial state is added to the $openSet$, similar to BFS the $openSet$ is iterated through until it finds a goal state or there are no more states to explore, implying no solutions. The most promising state is retrieved from the $openSet$ (the state with the lowest $F$ score) and assigned to $currentState$. This state is then removed from the $openSet$ and added to the $closedSet$. The $currentState$ is checked to see whether it matches the goal state and returned if so. From the $currentState$ all the possible moves are found and denoted as $neighbours$, each $neighbour$ is checked against the $closedSet$ to make sure the state hasn't already been expanded. The $neighbour$ is then checked against the $openSet$ and if the $openSet$ contains $neighbour$ the $G$ values are compared to check which version of the state has the best route from the starting position see Algorithm~\ref{Astar}.


	\begin{algorithm}
	\caption{A*}\label{Astar}
	\begin{algorithmic}[1]
		\State $g(state)$ \Comment The cost to reach the current state
		\State $h(state)$ \Comment Estimated cost of the cheapest path from state to goal
		\State $f(state) \gets g(state)+h(state)$
		\State $neighbours(state)$ \Comment Expands possible moves from current state ordered by g + h
		
		\Procedure{AStar}{$startState$}
		\State $closedSet \gets \textit{empty set}$
		\State $openSet \gets \textit{empty set}$
		\State $openSet.add(startState)$
		\While{$openSet \textbf{ is not } empty$}
		\State $currentState \gets state\   \textbf{in}\ openSet\ with\ lowest\ f\ value$
		\State $openSet.remove(currentState)$
		\State $closedSet.add(currentState)$
		\If {$currentState = goal$}
		\State \textbf{return} $currentState$
		\EndIf
		\For{$neighbour \textbf{ in } neighbours(currentState)$}	
		\If{$neighbour \textbf{ not in } closedSet$}
		\If{$neighbour \textbf{ in } openSet$}
		\If{$g(currentState) < g(neighbour)$} 
		\State$g(neighbour) \gets g(currentState)$
		\EndIf	
		\Else
		\State $openSet.add(neighbour)$	
		\EndIf
		\EndIf
		
		\EndFor
		\EndWhile
		\EndProcedure
	\end{algorithmic}
\end{algorithm}



\subsubsection{Manhattan Distance and Linear Conflict}
My tests displayed in Table 4 show that A* search with the linear conflict heuristic improves the performance of A* with Manhattan distance for the 8-tile puzzle. On average A* with linear conflict would take around 1ms longer than A* with Manhattan distance, until the number of moves required to solve the puzzle were greater than 25, as this showed a substantial decline in time when comparing the linear conflict to the Manhattan heuristic. This implies that the performance of linear conflict exceeds the performance of Manhattan distance when the state space grows, so the more difficult the puzzle the greater the gap in performance between the two heuristics becomes.
\begin{center}
	\captionof{table}{Manhattan Distance Vs. Linear Conflict - A*}
	\begin{tabular}{|l|r|r|r|r|r|r|} \cline{2-7}
		
		\multicolumn{1}{c}{} & \multicolumn{3}{|c|}{Manhattan Distance} &
		\multicolumn{3}{|c|}{Linear Conflict} \\ \hline
		Min Moves & Time(ms) & Mean Memory & States & Time(ms) & Mean Memory & States \\	\hline \hline
		5 & 0.3170 & 4.0267 & 6               & 1.3602 & 4.0267 & 6 \\
		10 & 0.4326 & 4.0267 & 11             & 1.3391 & 4.0267 & 11 \\
		15 & 0.5599 & 4.0267 & 16             & 1.4346 & 4.0267 & 16 \\
		20 & 0.7307 & 4.0267 & 21             & 1.6672 & 4.0267 & 21 \\
		25 & 4.4329 & 4.0267 & 141            & 4.2708 & 4.0267 & 103\\
		30 & 532.9964 & 4.9195 & 5640         & 277.7063& 5.3643 &3752\\
		\hline
	
	\end{tabular}

\end{center}
 As the state space grows exponentially according to the depth the growth is smaller for the A* with linear conflict, this is because the heuristic is a more accurate representation of the displacement of the tiles, thus the H value is always larger than or equal to the H value of the Manhattan Distance. Table 5 shows the difference in H value for 10 calculations of both algorithms and how the linear conflict is nearly always larger than the Manhattan distance.
 
  Table 4 shows the exponential growth by the number of states the algorithm expanded. The average number of States for the Manhattan distance heuristic from 5 to 30 moves is 972.5, whereas linear conflict's average is 651.


\begin{table}[ht]
	\caption{Manhattan Distance Vs Linear Conflict Values}
	\begin{center}
		\begin{tabular}{crr} \hline
			State & Manhattan Distance  & Linear Conflict    \\ \hline
			1  & 20 & 22  \\
			2 & 20  & 26 \\ 
			3 & 20 & 24  \\ 
			4 & 22 & 24  \\
		    5 & 21  & 23 \\ 
			6 & 21 & 23  \\ 
			7 & 21 & 23  \\ 
			8 & 21 & 23  \\ 
			9 & 22 & 22  \\ 
			10 & 20 & 22  \\ \hline
		\end{tabular}
	\end{center}
\end{table}


\section{Fifteen Tile Puzzle}
I initially tested the A* Manhattan distance and the A* linear conflict on the fifteen tile puzzle, however could only get results for puzzle states which require a small number of moves to find the goal. The reasoning for the lack of results is the large amount of States that the $CLOSEDSET$ has to store. 

A* uses breadth-first traversal thus the number of states that are stored increases exponentially with depth. Finding an algorithm which would require less memory but still had the benefits of a heuristic search was necessary. This is similar to the previous scenario when considering how to reduce the memory used in breadth-first by taking depth-first search's memory used as inspiration.

The memory used by Depth-first iterative deepening is linear with respect to the depth. In theory DFID could be used to solve the 15-puzzle without running out of memory, however taking the results found in Table 3, the time taken to reach the goal state for any random instance of the fifteen tile puzzle would be unreasonable.


\subsection{Iterative Deepening A*}
Iterative-deepening A* (IDA*) eradicates the memory complication of A* by using depth-first traversal, without sacrificing solution optimality at the cost of increasing the time taken. Each iteration of A* is a complete depth-first search that keeps track of the cost, $f(n) = g(n) = h(n)$, of each node generated. If an expanded node's cost generated exceeds a threshold for that iteration, its path is cut off and the search backtracks before continuing. IDA* ranks states the same way as A*: The expected cost of a state is the cost of reaching said state plus the heuristic's estimate of the cost of reaching the nearest goal state. The maximum expected cost is assigned to the heuristic cost of the starting state, states which have a lower cost than the starting state are traversed and states with a higher expected cost are discarded. 


If IDA* has searched all states lower than the current maximum without finding the goal state then it increases the maximum to the lowest value of the discarded states and begins the search again. The goal state is admissible, the current maximum cost will never be higher than the lowest cost solution, thus IDA* with an admissible heuristic will always find the lowest cost solution.  IDA* searches many nodes multiple times thus is slower than A*. Hence, A* should be used on smaller applications with lower memory requirements.

	
\begin{algorithm}
	\caption{Iterative Deepening A Star}\label{IDAStar}
	\begin{algorithmic}[1]
		
		\State $state$ \Comment The current puzzle configuration
		\State $g(state)$ \Comment The cost to reach the current state
		\State $h(state)$ \Comment Estimated cost of the cheapest path from state to goal
		\State $f(state) \gets g(state)+h(state)$
		\State $neighbours(state)$ \Comment Expands possible moves from current state ordered by g + h
		\Statex
		\Procedure{IDAStar}{$state$}
		\State $bound \gets f(state)$
		\While{ \textbf{ not } found}\Comment{Loops until a solution is found}
		\State $ bound \gets DLS(state, bound)$	\Comment Performs a bounded depth-first search 
		\EndWhile\label{}
		\EndProcedure
		\Statex
		
		\Procedure{DLS}{$state, bound$}
		\If{$f(state) > bound$}
		\State \textbf{return} $f(state)$
		\EndIf	
		
		\If{$h(state) = 0$} \Comment No more moves needed to reach goal state
		\State \textbf{return} $found$
		\EndIf
		\State $min \gets \infty$	
		\For{$neighbour \textbf{ in } neighbours(state)$}	
		\State $temp \gets DLS(neighbour, bound)$
		
		\If{$temp < min}$
		\State $min \gets temp $
		\EndIf
		\EndFor
		\State \textbf{return} $min$\Comment{Returns the smallest of the neighbours}
		\EndProcedure
		
	\end{algorithmic}
\end{algorithm}

The IDAStar algorithm is very similar to to DFID; IDAStar iteratively deepens dependent on the $F$ value rather than a fixed depth. The initial $bound$ is assigned to the $F$ score of state, which is also just the $H$ value as $G$ is inherently 0 as no moves have been made to get to this state. A depth-first limited search is then executed to the specified threshold. If the $F$ value of the current state is greater than the $bound$ this is returned and assigned to the new $bound$. If the $H$ estimate of the state is 0, no more moves are required to get to the goal state thus the solution is found. Similar to A* the neighbour with the smallest $F$ value is prioritised see Algorithm~\ref{IDAStar}


\captionof{table}{Iterative Deepening A* Results}
\begin{center}

	\begin{tabular}{|l|r|r|r|r|} \cline{2-5}
		
		\multicolumn{1}{c}{} & \multicolumn{2}{|c|}{Linear Conflict} &
		\multicolumn{2}{|c|}{Manhattan Distance} \\ \hline
		Min Moves & Time(ms) & States Expanded & Time(ms) & States Expanded \\	\hline \hline
		5  & 2.2913 & 6                        & 2.4060       &          6            \\
		10 & 2.3751  & 13                      & 2.3739       &         11            \\
		15 & 2.8140 & 24                       & 2.5081          &      16            \\
		20 & 11.3692 & 919                     & 8.0932        &        768           \\
		25&  21.9585  & 10420                  & 37.5986        &       25272         \\
		30& 117.3271 & 91471                   & 159.5604        &      217239        \\
		35  & 215.4406 & 231508                & 287.0284        &      482893        \\
		40& 78.972869 & 61141                  & 120.4332          &    110903        \\
		45 & 1750.4441 & 2468006               & 7111.9494        &     14202684      \\
		50& 9162.8202 & 13704525               & 17143.5055         &   36202294       \\
		55 & 6233.2757 & 9132143               & 13912.0609        &    29537720       \\
		60 & 61771.3520 & 87466771             & 277232.1371      &     596363837      \\
		\hline
		
	\end{tabular}
	
\end{center}




\begin{figure}[!ht]
	
	\begin{subfigure}[t]{.5\textwidth}
		\begin{tikzpicture}
		\begin{axis}[
	 width=\textwidth,
	axis lines = left,
	xlabel = Min Moves,
		]
	\addplot coordinates{(5,2.5849)(10,3.7)(15,4.5849)(20,9.8439)(25,13.347)(30,16.481)(35,17.8207)(40,15.899)(45,21.234)(50,23.708)(55,23.122)(60,26.382217)};
	
	\addplot
	coordinates{(5,2.5849)(10,3.459)(15,4)(20,9.5849)(25,14.62626)(30,17.72892)(35,18.881)(40,16.7589)(45,23.7596)(50,25.10958)(55,24.81606)(60,29.15162)};
		
		\end{axis}
		\end{tikzpicture}
		\caption{Log Of The States Expanded}
	\end{subfigure}
	\begin{subfigure}[t]{.5\textwidth}
		\begin{tikzpicture}
		\begin{axis}[
		width=\textwidth,
		axis lines = left,
		xlabel = Min Moves,
		]
	\addplot coordinates{(5,1.1961)(10,1.2479)(15,1.492622)(20,3.507059)(25,4.456708)(30,6.874392)(35,7.7511)(40,6.303)(45,10.773)(50,13.161)(55,12.60577)(60,15.91465)};
	
	\addplot
	coordinates{(5,1.2666)(10,1.2472)(15,1.3265)(20,3.01)(25,5.232)(30,7.31795)(35,8.16505)(40,6.912089)(45,12.79603)(50,14.0653)(55,13.76405)(60,18.08073)};
		\end{axis}
		\end{tikzpicture}
		\caption{Log Of The Time}
	\end{subfigure}
	\caption{Logarithmic Comparison Of IDA* Fifteen Tile}
\end{figure}

The time complexity of IDA* is measured by the number of nodes expanded, provided each node can be expanded and its successors evaluated in constant time, the asymptotic time complexity of IDA* is the total nodes expanded. Otherwise it is the product of the total number of nodes and the time taken to expand each. Provided the heuristic is consistent (see 4.2), IDA* must expand all nodes with the $f$ value less than or equal to $c$ which  is the cost of an optimal solution $f(n) \leq c$. This is shown in my code by \begin{verbatim}
if(value <= currentCostBound)
\end{verbatim}

On the final iteration of IDA* the cost threshold is equal to $c$, the cost of an optimal solution.\citep{DBLP:journals/ai/KorfRE01}.

The results gathered show that in Table 6 and Figure 4 further compliment the findings of the contrast in efficiency of the two heuristics Manhattan distance and Linear conflict. With the number of states expanded increasing the time taken to find the goal state increases and thus the difference between the linear conflict and Manhattan Distance widens.


\section{Pattern Databases}




\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\textwidth]{parity}
	\captionsetup{justification=centering}
	\caption{Puzzle Parity}
\end{figure}

Here is some code written to calculate the sum of the inversions in an array, from this we can determine whether it is solvable by following the guidelines above.


\subsection{Non-Additive Pattern Databases}
A Pattern Database stores a collection of solutions to sub-problems that much be achieved to solve the overall problem. They are admissible heuristic functions implemented as lookup tables that store the lengths of optimal solutions for sub-problem instances. \citep{DBLP:journals/jair/FelnerKMH07}.

The initial pattern database applied to the fifteen tile as shown in Figure 6 is the fringe pattern. The heuristic is estimated dependent on the current positions of the fringe tiles and the blank, the remaining tiles are disregarded. These values are precomputed and stored in a database and are called upon when a heuristic estimate is needed. The total number of possible permutations of fringe tiles and blank is $16!/(16-8)!=518,918,400$. 

To retrieve all possible permutations of the fringe tiles a single breadth-first search must be executed, commencing at the goal state. Tiles which are not fringe are all equivalent and in the database the positioning of the fringe tiles and the blank are stored along with the number of moves taken to get to that state.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.30\textwidth]{fringe}
	\captionsetup{justification=centering}
	\caption{Fringe Database Pattern For Fifteen Tile}
\end{figure}

Once the breadth-first search has finished and it has trawled through all $518,914,400$ states, using IDA* the heuristic function determines the positions of the fringe tiles and the blank which are used as an index to the row with the given configuration in the database, the value for that row is then retrieved and used as the heuristic value.

\subsubsection{Non-Additive Pattern Database Limitations}
If the tiles are divided into disjoint groups, the best way to combine them admissibly is to take the maximum of their values; non-additive pattern database values include all moves needed to solve the configuration including moves of other tile. \citep{DBLP:journals/corr/abs-1107-0050}.

Another major issue is space required to store all possible states. When considering the 15 tile: provided each row in the database is 1 byte and there are 519,914,400 rows that's a total of 519Mb, and the time taken to perform the breadth-first search is extensive, Table1: Breadth-First Search Analysis shows that the time taken to expand just 65638 nodes was 34621.883ms.

Scalability is another issue regarding non-additive pattern databases. Take Figure 7 as an example, if we were to scale up to the twenty-five tile puzzle and performed the same calculations for taking the fringe: $25!/(25-10)!=1.1861676e+13$, provided each row in the database is 1 byte as previously stated, the summation is roughly 12 Terabytes worth of memory.



\begin{figure}[ht]
	\centering
	\includegraphics[width=0.35\textwidth]{fringe15}
	\captionsetup{justification=centering}
	\caption{Fringe Database Pattern For The Twenty-five Tile}
\end{figure}

\subsection{Statically-Partitioned Additive Database Heuristics}
In order to develop a statically-partitioned additive database for the sliding tile puzzle, the tiles were partitioned into disjoint groups, meaning each tile is placed in a group and only appears in that group. The same method as explained in 6.2 for finding all the states was computed for each subset; a breadth-first search from the goal state with all possible configurations of each tile in the disjoint groups and the number of moves required to get to the goal state. For a particular state in the search, for each position of the tiles an index was computed for the corresponding row in the database, then retrieved the number of moves required to solve the tiles in that group and added this value to each value of the other disjoint groups. The summed total of these values will always be equal to or larger than the Manhattan distance of the state as it considers the interactions between tiles within a given subset.	

I initially chose to implement the 6-6-3 partitioning as hypothesised it will be the best compromise between speed and memory in comparison with other possible solutions, Figure 8 shows the partitioning. The first two images display the fifteen tile with the subsets comprising of 6 tiles, $2\times(16!/(16-6)!)= 11531520$ states to be stored, the final subset requires $16!/(16-3)!=3360$ states stored that's a total of $11534880$ rows in the database. 


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\textwidth]{15tile}
	\captionsetup{justification=centering}
	\caption{6-6-3 Partioning}
\end{figure}
\section{Program Architecture}

\subsection{Initial Implementation}

When a node is being expanded it is necessary to find its neighbours. Neighbours for the sliding-tile puzzle represent the possible moves from the current configuration, each state has a minimum of 2 neighbours and a maximum of 4. Figure 1 shows the possible moves from current state and how the direction variable would be stored ready for output. 

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\textwidth]{moves}
	\captionsetup{justification=centering}
	\caption{Finding possible moves}
\end{figure}



\section{Results}
\subsection{BFS}


Table 1 shows the results of the 8-puzzle using breadth-first search. The tests were performed on all $9!/2=181440$ states, an initial BFS was executed from the goal configuration and each state along with the number of moves required was stored. States were split up into testing lists dependent on the number of moves as shown by column 1 and 2. Tests were then executed using breadth-first search on each state, column 3 displays the average number of nodes expanded before finding the goal state, column 4 is the average time taken to solve a given state and column 5 shows the total time taken to solve all states in the specific testing list.
\begin{table}[ht]
	\caption{Breadth-First Search Analysis: 8-puzzle}
	\begin{center}
		\begin{tabular}{crrrr} \hline
			Min Moves & No. States & Avg Nodes Expanded & Avg. Time(ms) & Total Time(ms) \\ \hline
			0-4  & 31 & 747.19$\pm$435.76 & 0.5483 & 18 \\
			5-9 & 389 &4249.35$\pm$4277.99& 1.0668 & 432.0 \\ 
			10-14 & 4347 &  23257.75$\pm$20745.99& 5.7888 & 25164  \\ 
			15-19 & 33042& 58446.06$\pm$35484.49 & 17.7823 & 587563 \\ 
			20-24 & 102326& 114724.84$\pm$36410.64 & 41.0058 & 4195959  \\ 
			25-29 & 41082& 162772.14$\pm$15654.31 & 60.0550 & 2467181 \\ 
			30+ & 223& 180524.70$\pm$548.90 & 67.3542 & 15006\\ \hline
		\end{tabular}
	\end{center}
\end{table}

\begin{table}[ht]
	\caption{Breadth-First Search Analysis: 8-puzzle (10000 Random States)}
	\begin{center}
		\begin{tabular}{crr} \hline
			Average Moves & Avg Nodes Expanded & Avg. Time(ms)\\ \hline
			21.7142$\pm$0.065 & 89201.4297 & 29.7373\\ \hline
		\end{tabular}
	\end{center}
\end{table}
\begin{figure}[!ht]
	\begin{subfigure}[t]{0.5\textwidth}
		\begin{tikzpicture}
		\begin{axis}[
		width=\textwidth,
		ymin=0, ymax=25000,
		minor y tick num = 3,
		area style,
		xlabel = No. Moves,
		ylabel = No. States,
		]
		\addplot+[ybar interval,mark=no] plot coordinates { 	
			(1,2)
			(2,4)
			(3,8)
			(4,16)
			(5,20)
			(6,39)	
			(7,62)
			(8,116)
			(9,152)
			(10,286)
			(11,396)
			(12,748)
			(13,1024)
			(14,1893)
			(15,2512)
			(16,4485)
			(17,5639)
			(18,9529)
			(19,10878)
			(20,16993)
			(21,17110)
			(22,23952)
			(23,20224)
			(24,24047)
			(25,15578)
			(26,14650)
			(27,6274)
			(28,3910)
			(29,760)
			(30,221)
			(31,2)		 };
		\end{axis}
		\end{tikzpicture}
	\end{subfigure}
	\begin{subfigure}[t]{0.5\textwidth}
		\begin{tikzpicture}
		\begin{axis}[
		width=\textwidth,
		ymin=0, ymax=1175494,
		minor y tick num = 3,
		area style,
		xlabel = No. Moves,
		ylabel = Summed Time(ms),
		]
		\addplot+[ybar interval,mark=no] plot coordinates{
			(1,0)
			(2,0)
			(3,0)
			(4,0)
			(5,2)
			(6,3)	
			(7,8)
			(8,19)
			(9,30)
			(10,61)
			(11,108)
			(12,251)
			(13,587)
			(14,1554)
			(15,3358)
			(16,9354)
			(17,19800)
			(18,49859)
			(19,98138)
			(20,209503)
			(21,330907)
			(22,708861)
			(23,784197)
			(24,1065494)
			(25,862847)
			(26,867818)
			(27,396454)
			(28,248861)
			(29,50164)
			(30,14541)
			(31,133)
		};
		\end{axis}
		\end{tikzpicture}
	\end{subfigure}%
	
	\caption{A representation of the number of states that require a specific amount of moves to be solved optimally in the 8-tile and the summed time taken for all these states to be solved}
\end{figure}


\begin{figure}[!ht]
	\centering
	\begin{subfigure}[t]{0.5\textwidth}
		\begin{tikzpicture}
		\begin{axis}[
		width=\textwidth,
		xlabel = No. Moves,
		ylabel = Average Time(ms),
		]
		\addplot[error bars/.cd, y dir=both, y explicit, ] coordinates{
			(2,0)
			(3,0)
			(4,0)
			(5,0.0625)
			(6,0.07)	
			(7,0.12903)
			(8,0.16379)
			(9,0.19737)
			(10,0.21329)
			(11,0.27273)
			(12,0.33556)
			(13,0.57324)
			(14,0.82092)
			(15,1.33678)
			(16,2.08562)
			(17,3.51188)
			(18,5.23234)
			(19,9.0217)
			(20,12.32878)
			(21,19.33998)
			(22,29.59507)
			(23,38.77556)
			(24,44.30881)
			(25,55.38882)
			(26,59.60288)
			(27,63.18999)
			(28,63.64731)
			(29,66.00526)
			(30,65.79638)
			(31,66.5)
		};
		\end{axis}
		\end{tikzpicture}
	\end{subfigure}%
	\begin{subfigure}[t]{0.5\textwidth}
		\begin{tikzpicture}
		\begin{axis}[
		width=\textwidth,
		xlabel = No. Moves,
		ylabel = Mean Nodes Expanded,
		]
		\addplot[error bars/.cd, y dir=both, y explicit, ] coordinates{
			(1,3.5)
			(2,8.25)
			(3,15.625)
			(4,25)
			(5,46.9)
			(6,79.87179)	
			(7,142.03226)
			(8,222.75)
			(9,396.56579)
			(10,607.36364)
			(11,1033.95707)
			(12,1580.87032)
			(13,2689.3877)
			(14,4068.70417)
			(15,6816.66521)
			(16,10077.94314)
			(17,16304.61352)
			(18,23252.76262)
			(19,35532.59423)
			(20,47973.72595)
			(21,68096.92613)
			(22,86105.56809)
			(23,111406.96737)
			(24,129960.55254)
			(25,151666.94146)
			(26,163973.55021)
			(27,174731.22792)
			(28,178683.9913)
			(29,180883.49474)
			(30,181336.30769)
			(31,181439.5)
		};
		\end{axis}
		\end{tikzpicture}
	\end{subfigure}
	\caption{8-tile analysis using breadth-first search to display how the minimum number of moves required to reach the goal state affects the time(ms) and the number of nodes expanded}
\end{figure} 





\clearpage
\bibliography{bibfile}


\appendix
\clearpage






\end{document}

